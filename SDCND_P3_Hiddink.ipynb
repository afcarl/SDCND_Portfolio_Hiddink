{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ScreenShot](images/loading_screen.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 - Behavioral Cloning\n",
    "### _How to Train a Deep Neural Network to Drive a Simulated Car_ \n",
    "#### Please refer to this repository's README.md for a detailed explanation of the project: https://github.com/nhiddink/CarND_P3_Behavioral_Cloning/blob/master/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# http://pandas.pydata.org/\n",
    "import pandas as pd\n",
    "\n",
    "# http://www.numpy.org/\n",
    "import numpy as np\n",
    "\n",
    "# http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_image_display/py_image_display.html\n",
    "import cv2\n",
    "\n",
    "# http://matplotlib.org/\n",
    "import matplotlib\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# http://scikit-learn.org/stable/\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# https://keras.io/\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout,Convolution2D,MaxPooling2D,Flatten,Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Entry from driving_log.csv: \n",
      "                                   center  \\\n",
      "0  IMG/center_2016_12_01_13_30_48_287.jpg   \n",
      "\n",
      "                                    left  \\\n",
      "0   IMG/left_2016_12_01_13_30_48_287.jpg   \n",
      "\n",
      "                                    right  steering  throttle  brake     speed  \n",
      "0   IMG/right_2016_12_01_13_30_48_287.jpg       0.0       0.0    0.0  22.14829  \n"
     ]
    }
   ],
   "source": [
    "# Declare variables\n",
    "folder = './data/'\n",
    "csv_path = 'driving_log.csv'\n",
    "\n",
    "# Load data from driving_log.csv using Pandas\n",
    "training_data = pd.read_csv(folder + csv_path, delimiter=None, header='infer', names=None)\n",
    "print('Sample Entry from driving_log.csv: \\n{}'.format(training_data.head(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sets split and converted.\n"
     ]
    }
   ],
   "source": [
    "X_train = training_data[['left','center','right']]\n",
    "Y_train = training_data['steering']\n",
    "\n",
    "# Split training, validation, and test sets\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Remove pandas index and convert to matrix\n",
    "X_left  = X_train['left'].as_matrix()\n",
    "X_right = X_train['right'].as_matrix()\n",
    "X_train = X_train['center'].as_matrix()\n",
    "X_valid = X_valid['center'].as_matrix()\n",
    "\n",
    "# Remove pandas index and convert to float32 matrix\n",
    "Y_train = Y_train.as_matrix()\n",
    "Y_train = Y_train.astype(np.float32)\n",
    "Y_valid = Y_valid.as_matrix()\n",
    "Y_valid = Y_valid.astype(np.float32)\n",
    "\n",
    "print('Data sets split and converted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sets shuffled.\n"
     ]
    }
   ],
   "source": [
    "# Shuffle data sets\n",
    "X_left, X_right, X_train, Y_train = shuffle(X_left, X_right, X_train, Y_train, random_state=0)\n",
    "print('Data sets shuffled.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_next_image(ex, value, X_train, X_left, X_right, Y_train):\n",
    "    offset = 1.2\n",
    "    dist = 20.0\n",
    "    steering = Y_train[ex]\n",
    "    \n",
    "    if value == 0:\n",
    "        image = plt.imread(folder + X_left[ex].replace(' ',''))\n",
    "        dsteering = offset / dist * 360 / (2 * np.pi) / 25.0\n",
    "        steering += dsteering\n",
    "    elif value == 1:\n",
    "        image = plt.imread(folder + X_train[ex].replace(' ',''))\n",
    "    elif value == 2:\n",
    "        image = plt.imread(folder + X_right[ex].replace(' ',''))\n",
    "        dsteering = -offset / dist * 360 / ( 2 * np.pi) / 25.0\n",
    "        steering += dsteering\n",
    "    else:\n",
    "        print ('Invalid value :', value )\n",
    "    \n",
    "    return image, steering\n",
    "\n",
    "def random_crop(image, steering=0.0, tx_lower=-20, tx_upper=20, ty_lower=-2, ty_upper=2, rand=True):\n",
    "    shape = image.shape\n",
    "    col_start, col_end = abs(tx_lower), shape[1]-tx_upper\n",
    "    horizon = 60;\n",
    "    bonnet = 136\n",
    "    if rand:\n",
    "        tx= np.random.randint(tx_lower,tx_upper+1)\n",
    "        ty= np.random.randint(ty_lower,ty_upper+1)\n",
    "    else:\n",
    "        tx, ty = 0, 0\n",
    "    \n",
    "    random_crop = image[horizon + ty : bonnet + ty, col_start + tx : col_end + tx, :]\n",
    "    image = cv2.resize(random_crop, (64,64), cv2.INTER_AREA)\n",
    "     \n",
    "    if tx_lower != tx_upper:\n",
    "        dsteering = -tx/(tx_upper-tx_lower)/3.0\n",
    "    else:\n",
    "        dsteering = 0\n",
    "    steering += dsteering\n",
    "    \n",
    "    return image, steering\n",
    "\n",
    "def random_shear(image,steering,shear_range):\n",
    "    rows, cols, ch = image.shape\n",
    "    dx = np.random.randint(-shear_range, shear_range + 1)\n",
    "    random_point = [cols / 2 + dx, rows / 2]\n",
    "    p1 = np.float32([[0, rows],[cols, rows],[cols / 2, rows / 2]])\n",
    "    p2 = np.float32([[0, rows],[cols, rows],random_point])\n",
    "    dsteering = dx / (rows / 2) * 360 / (2 * np.pi * 25.0) / 6.0    \n",
    "    M = cv2.getAffineTransform(p1, p2)\n",
    "    image = cv2.warpAffine(image, M, (cols, rows), borderMode=1)\n",
    "    steering += dsteering\n",
    "    return image, steering\n",
    "\n",
    "def random_brightness(image):\n",
    "    image1 = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    random_bright = 0.8 + 0.4 * (2 * np.random.uniform() - 1.0)    \n",
    "    image1[:,:,2] = image1[:, :, 2] * random_bright\n",
    "    image1 = cv2.cvtColor(image1, cv2.COLOR_HSV2RGB)\n",
    "    return image1\n",
    "\n",
    "def random_flip(image, steering):\n",
    "    coin=np.random.randint(0, 2)\n",
    "    if coin==0:\n",
    "        image, steering=cv2.flip(image, 1), -steering\n",
    "    return image, steering\n",
    "        \n",
    "def generate_training_example(X_train, X_left, X_right, Y_train):\n",
    "    ex = np.random.randint(0, len(Y_train))\n",
    "    value = np.random.randint(0, 3)\n",
    "    image,steering = read_next_image(ex, value, X_train, X_left, X_right, Y_train)\n",
    "    image,steering = random_shear(image, steering, shear_range=100)   \n",
    "    image,steering = random_crop(image, steering, tx_lower=-20, tx_upper=20, ty_lower=-10, ty_upper=10)\n",
    "    image,steering = random_flip(image, steering)\n",
    "    #image = random_brightness(image)\n",
    "    return image,steering\n",
    "\n",
    "def get_validation_set(X_valid, Y_valid):\n",
    "    X = np.zeros((len(X_valid), 64, 64, 3))\n",
    "    Y = np.zeros(len(X_valid))\n",
    "    for i in range(len(X_valid)):\n",
    "        x, y = read_next_image(i,1,X_valid,X_valid,X_valid,Y_valid)\n",
    "        X[i], Y[i] = random_crop(x,y,tx_lower=0,tx_upper=0,ty_lower=0,ty_upper=0)\n",
    "    return X, Y\n",
    "    \n",
    "def generate_train_batch(X_train, X_left, X_right, Y_train, batch_size=32):\n",
    "    batch_images = np.zeros((batch_size, 64, 64, 3))\n",
    "    batch_steering = np.zeros(batch_size)\n",
    "    while 1:\n",
    "        for i_batch in range(batch_size):\n",
    "            x, y = generate_training_example(X_train, X_left, X_right, Y_train)\n",
    "            batch_images[i_batch] = x\n",
    "            batch_steering[i_batch] = y\n",
    "        yield batch_images, batch_steering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train data type : object\n",
      "Y_train data type : float32\n",
      "X_valid data type : float64\n",
      "Y_valid data type : float64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 200\n",
    "train_generator = generate_train_batch(X_train, X_left, X_right, Y_train, batch_size)\n",
    "X_valid, Y_valid = get_validation_set(X_valid, Y_valid)\n",
    "\n",
    "print('X_train data type :',X_train.dtype)\n",
    "print('Y_train data type :',Y_train.dtype)\n",
    "print('X_valid data type :',X_valid.dtype)\n",
    "print('Y_valid data type :',Y_valid.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 64, 64, 3)     0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 16, 16, 32)    6176        lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 16, 16, 32)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 4, 4, 64)      131136      activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "relu2 (Activation)               (None, 4, 4, 64)      0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 2, 2, 128)     131200      relu2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 2, 2, 128)     0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 2, 2, 128)     65664       activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 2, 2, 128)     0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 512)           0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 512)           0           flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           65664       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 128)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 128)           0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 128)           16512       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1)             129         dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 416,481\n",
      "Trainable params: 416,481\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/127.5 - 1.0,input_shape=(64,64,3)))\n",
    "model.add(Convolution2D(32, 8,8 ,border_mode='same', subsample=(4,4)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 8,8 ,border_mode='same',subsample=(4,4)))\n",
    "model.add(Activation('relu',name='relu2'))\n",
    "model.add(Convolution2D(128, 4,4,border_mode='same',subsample=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(128, 2,2,border_mode='same',subsample=(1,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model.json & model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "20000/20000 [==============================] - 42s - loss: 0.0592 - val_loss: 0.0178\n",
      "Epoch 2/30\n",
      "20000/20000 [==============================] - 40s - loss: 0.0292 - val_loss: 0.0121\n",
      "Epoch 3/30\n",
      "20000/20000 [==============================] - 41s - loss: 0.0244 - val_loss: 0.0120\n",
      "Epoch 4/30\n",
      "20000/20000 [==============================] - 40s - loss: 0.0235 - val_loss: 0.0122\n",
      "Epoch 5/30\n",
      "20000/20000 [==============================] - 40s - loss: 0.0220 - val_loss: 0.0114\n",
      "Epoch 6/30\n",
      "20000/20000 [==============================] - 40s - loss: 0.0213 - val_loss: 0.0125\n",
      "Epoch 7/30\n",
      "20000/20000 [==============================] - 40s - loss: 0.0205 - val_loss: 0.0126\n",
      "Epoch 8/30\n",
      "20000/20000 [==============================] - 40s - loss: 0.0202 - val_loss: 0.0130\n",
      "Epoch 9/30\n",
      "20000/20000 [==============================] - 40s - loss: 0.0201 - val_loss: 0.0123\n",
      "Epoch 10/30\n",
      "20000/20000 [==============================] - 40s - loss: 0.0197 - val_loss: 0.0132\n",
      "Epoch 11/30\n",
      "20000/20000 [==============================] - 40s - loss: 0.0201 - val_loss: 0.0123\n",
      "Epoch 12/30\n",
      "20000/20000 [==============================] - 39s - loss: 0.0186 - val_loss: 0.0122\n",
      "Epoch 13/30\n",
      "20000/20000 [==============================] - 39s - loss: 0.0192 - val_loss: 0.0124\n",
      "Epoch 14/30\n",
      "20000/20000 [==============================] - 40s - loss: 0.0185 - val_loss: 0.0124\n",
      "Epoch 15/30\n",
      "20000/20000 [==============================] - 40s - loss: 0.0180 - val_loss: 0.0121\n",
      "Epoch 16/30\n",
      "20000/20000 [==============================] - 41s - loss: 0.0180 - val_loss: 0.0111\n",
      "Epoch 17/30\n",
      "20000/20000 [==============================] - 40s - loss: 0.0180 - val_loss: 0.0132\n",
      "Epoch 18/30\n",
      "20000/20000 [==============================] - 40s - loss: 0.0178 - val_loss: 0.0124\n",
      "Epoch 19/30\n",
      "20000/20000 [==============================] - 40s - loss: 0.0184 - val_loss: 0.0121\n",
      "Epoch 20/30\n",
      "20000/20000 [==============================] - 39s - loss: 0.0179 - val_loss: 0.0117\n",
      "Epoch 21/30\n",
      "20000/20000 [==============================] - 40s - loss: 0.0179 - val_loss: 0.0128\n",
      "Epoch 22/30\n",
      "20000/20000 [==============================] - 40s - loss: 0.0182 - val_loss: 0.0122\n",
      "Epoch 23/30\n",
      "20000/20000 [==============================] - 40s - loss: 0.0175 - val_loss: 0.0123\n",
      "Epoch 24/30\n",
      "20000/20000 [==============================] - 41s - loss: 0.0173 - val_loss: 0.0120\n",
      "Epoch 25/30\n",
      "20000/20000 [==============================] - 40s - loss: 0.0172 - val_loss: 0.0122\n",
      "Epoch 26/30\n",
      "20000/20000 [==============================] - 41s - loss: 0.0175 - val_loss: 0.0108\n",
      "Epoch 27/30\n",
      "20000/20000 [==============================] - 40s - loss: 0.0174 - val_loss: 0.0119\n",
      "Epoch 28/30\n",
      "20000/20000 [==============================] - 41s - loss: 0.0167 - val_loss: 0.0113\n",
      "Epoch 29/30\n",
      "20000/20000 [==============================] - 40s - loss: 0.0169 - val_loss: 0.0112\n",
      "Epoch 30/30\n",
      "20000/20000 [==============================] - 40s - loss: 0.0170 - val_loss: 0.0110\n",
      "Training complete. Saving model and weights...\n",
      "Model and weights saved to home directory.\n"
     ]
    }
   ],
   "source": [
    "model_json = 'model.json'\n",
    "model_weights = 'model.h5'\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "restart = True\n",
    "if os.path.isfile(model_json) and restart:\n",
    "    try:\n",
    "        with open(model_json) as jfile:\n",
    "            model = model_from_json(json.load(jfile))\n",
    "            model.load_weights(model_weights)    \n",
    "        print('Loading trained model ...')\n",
    "    except Exception as e:\n",
    "        print('Unable to load model.', model_name, ':', e)\n",
    "        raise\n",
    "\n",
    "model.compile(optimizer=adam, loss='mse')\n",
    "\n",
    "EPOCHS = 30\n",
    "history = model.fit_generator(train_generator,\n",
    "                              samples_per_epoch=20000,\n",
    "                              nb_epoch=EPOCHS,\n",
    "                              validation_data=(X_valid,Y_valid),\n",
    "                              verbose=1)\n",
    "\n",
    "json_string = model.to_json()\n",
    "\n",
    "print('Training complete. Saving model and weights...')\n",
    "\n",
    "try:\n",
    "    os.remove(model_json)\n",
    "    os.remove(model_weights)\n",
    "except OSError:\n",
    "    pass   \n",
    "\n",
    "with open(model_json, 'w') as outfile:\n",
    "    json.dump(json_string, outfile)\n",
    "model.save_weights(model_weights)\n",
    "\n",
    "print('Model and weights saved to home directory.')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

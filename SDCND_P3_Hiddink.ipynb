{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# IMPORT STATEMENTS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "#import sys\n",
    "import cv2\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib.style.use('ggplot')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout,Convolution2D,MaxPooling2D,Flatten,Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import model_from_json\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>center</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>steering</th>\n",
       "      <th>throttle</th>\n",
       "      <th>brake</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG/center_2016_12_01_13_30_48_287.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_30_48_287.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_30_48_287.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.148290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG/center_2016_12_01_13_30_48_404.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_30_48_404.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_30_48_404.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.879630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG/center_2016_12_01_13_31_12_937.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_31_12_937.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_31_12_937.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.453011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG/center_2016_12_01_13_31_13_037.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_31_13_037.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_31_13_037.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.438419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG/center_2016_12_01_13_31_13_177.jpg</td>\n",
       "      <td>IMG/left_2016_12_01_13_31_13_177.jpg</td>\n",
       "      <td>IMG/right_2016_12_01_13_31_13_177.jpg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.418236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   center  \\\n",
       "0  IMG/center_2016_12_01_13_30_48_287.jpg   \n",
       "1  IMG/center_2016_12_01_13_30_48_404.jpg   \n",
       "2  IMG/center_2016_12_01_13_31_12_937.jpg   \n",
       "3  IMG/center_2016_12_01_13_31_13_037.jpg   \n",
       "4  IMG/center_2016_12_01_13_31_13_177.jpg   \n",
       "\n",
       "                                    left  \\\n",
       "0   IMG/left_2016_12_01_13_30_48_287.jpg   \n",
       "1   IMG/left_2016_12_01_13_30_48_404.jpg   \n",
       "2   IMG/left_2016_12_01_13_31_12_937.jpg   \n",
       "3   IMG/left_2016_12_01_13_31_13_037.jpg   \n",
       "4   IMG/left_2016_12_01_13_31_13_177.jpg   \n",
       "\n",
       "                                    right  steering  throttle  brake  \\\n",
       "0   IMG/right_2016_12_01_13_30_48_287.jpg       0.0       0.0    0.0   \n",
       "1   IMG/right_2016_12_01_13_30_48_404.jpg       0.0       0.0    0.0   \n",
       "2   IMG/right_2016_12_01_13_31_12_937.jpg       0.0       0.0    0.0   \n",
       "3   IMG/right_2016_12_01_13_31_13_037.jpg       0.0       0.0    0.0   \n",
       "4   IMG/right_2016_12_01_13_31_13_177.jpg       0.0       0.0    0.0   \n",
       "\n",
       "       speed  \n",
       "0  22.148290  \n",
       "1  21.879630  \n",
       "2   1.453011  \n",
       "3   1.438419  \n",
       "4   1.418236  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DECLARE VARIABLES & LOAD DATA\n",
    "\n",
    "data_dir = './data/'\n",
    "data_csv = 'driving_log.csv'\n",
    "model_json = 'model.json'\n",
    "model_weights = 'model.h5'\n",
    "\n",
    "training_data = pd.read_csv(data_dir+data_csv,names=None)\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train[:5]:  ['IMG/center_2016_12_01_13_39_58_081.jpg'\n",
      " 'IMG/center_2016_12_01_13_35_47_206.jpg'\n",
      " 'IMG/center_2016_12_01_13_42_14_300.jpg'\n",
      " 'IMG/center_2016_12_01_13_33_56_606.jpg'\n",
      " 'IMG/center_2016_12_01_13_38_30_847.jpg']\n",
      "Y_train[:5]:  [-0.44902581  0.0904655   0.         -0.40155399 -0.05026283]\n"
     ]
    }
   ],
   "source": [
    "# DECLARE VARIABLES & SPLIT TRAINING, VALIDATION, TEST SETS\n",
    "\n",
    "training_data[['left','center','right']]\n",
    "X_train = training_data[['left','center','right']]\n",
    "Y_train = training_data['steering']\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "X_left  = X_train['left'].as_matrix()\n",
    "X_right = X_train['right'].as_matrix()\n",
    "X_train = X_train['center'].as_matrix()\n",
    "X_val   = X_val['center'].as_matrix()\n",
    "Y_val   = Y_val.as_matrix()\n",
    "Y_train = Y_train.as_matrix()\n",
    "\n",
    "Y_train = Y_train.astype(np.float32)\n",
    "Y_val   = Y_val.astype(np.float32)\n",
    "\n",
    "\n",
    "if data_dir=='./data/udacity':\n",
    "    X_train = X_train.apply(lambda x: data_dir+'/'+x)\n",
    "    X_left = X_left.apply(lambda x: data_dir+'/'+x)\n",
    "    X_right = X_right.apply(lambda x: data_dir+'/'+x)\n",
    "\n",
    "print('X_train[:5]: \\n',X_train[:5])\n",
    "print('Y_train[:5]: \\n',Y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_next_image(m,lcr,X_train,X_left,X_right,Y_train):\n",
    "    # assume the side cameras are about 1.2 meters off the center and the offset to the left or right \n",
    "    # should be be corrected over the next dist meters, calculate the change in steering control\n",
    "    # using tan(alpha)=alpha\n",
    "\n",
    "    offset=1.0 \n",
    "    dist=20.0\n",
    "    steering = Y_train[m]\n",
    "    if lcr == 0:\n",
    "        image = plt.imread(data_dir+X_left[m].replace(' ',''))\n",
    "        dsteering = offset/dist * 360/( 2*np.pi) / 25.0\n",
    "        steering += dsteering\n",
    "    elif lcr == 1:\n",
    "        image = plt.imread(data_dir+X_train[m].replace(' ',''))\n",
    "    elif lcr == 2:\n",
    "        image = plt.imread(data_dir+X_right[m].replace(' ',''))\n",
    "        dsteering = -offset/dist * 360/( 2*np.pi)  / 25.0\n",
    "        steering += dsteering\n",
    "    else:\n",
    "        print ('Invalid lcr value :',lcr )\n",
    "    \n",
    "    return image,steering\n",
    "\n",
    "def random_crop(image,steering=0.0,tx_lower=-20,tx_upper=20,ty_lower=-2,ty_upper=2,rand=True):\n",
    "    # we will randomly crop subsections of the image and use them as our data set.\n",
    "    # also the input to the network will need to be cropped, but of course not randomly and centered.\n",
    "    shape = image.shape\n",
    "    col_start,col_end =abs(tx_lower),shape[1]-tx_upper\n",
    "    horizon=60;\n",
    "    bonnet=136\n",
    "    if rand:\n",
    "        tx= np.random.randint(tx_lower,tx_upper+1)\n",
    "        ty= np.random.randint(ty_lower,ty_upper+1)\n",
    "    else:\n",
    "        tx,ty=0,0\n",
    "    \n",
    "    #    print('tx = ',tx,'ty = ',ty)\n",
    "    random_crop = image[horizon+ty:bonnet+ty,col_start+tx:col_end+tx,:]\n",
    "    image = cv2.resize(random_crop,(64,64),cv2.INTER_AREA)\n",
    "    # the steering variable needs to be updated to counteract the shift \n",
    "    if tx_lower != tx_upper:\n",
    "        dsteering = -tx/(tx_upper-tx_lower)/3.0\n",
    "    else:\n",
    "        dsteering = 0\n",
    "    steering += dsteering\n",
    "    \n",
    "    return image,steering\n",
    "\n",
    "def random_shear(image,steering,shear_range):\n",
    "    rows,cols,ch = image.shape\n",
    "    dx = np.random.randint(-shear_range,shear_range+1)\n",
    "    #    print('dx',dx)\n",
    "    random_point = [cols/2+dx,rows/2]\n",
    "    pts1 = np.float32([[0,rows],[cols,rows],[cols/2,rows/2]])\n",
    "    pts2 = np.float32([[0,rows],[cols,rows],random_point])\n",
    "    dsteering = dx/(rows/2) * 360/(2*np.pi*25.0) / 6.0    \n",
    "    M = cv2.getAffineTransform(pts1,pts2)\n",
    "    image = cv2.warpAffine(image,M,(cols,rows),borderMode=1)\n",
    "    steering +=dsteering\n",
    "    \n",
    "    return image,steering\n",
    "\n",
    "def random_brightness(image):\n",
    "    image1 = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    random_bright = 0.8 + 0.4*(2*np.random.uniform()-1.0)    \n",
    "    image1[:,:,2] = image1[:,:,2]*random_bright\n",
    "    image1 = cv2.cvtColor(image1,cv2.COLOR_HSV2RGB)\n",
    "    return image1\n",
    "\n",
    "def random_flip(image,steering):\n",
    "    coin=np.random.randint(0,2)\n",
    "    if coin==0:\n",
    "        image,steering=cv2.flip(image,1),-steering\n",
    "    return image,steering\n",
    "        \n",
    "\n",
    "def generate_training_example(X_train,X_left,X_right,Y_train):\n",
    "    m = np.random.randint(0,len(Y_train))\n",
    "#    print('training example m :',m)\n",
    "    lcr = np.random.randint(0,3)\n",
    "    #lcr = 1\n",
    "#    print('left_center_right  :',lcr)\n",
    "    image,steering = read_next_image(m,lcr,X_train,X_left,X_right,Y_train)\n",
    "#    print('steering :',steering)\n",
    "#    plt.imshow(image)\n",
    "    image,steering = random_shear(image,steering,shear_range=100)\n",
    "#    print('steering :',steering)\n",
    "#    plt.figure()\n",
    "#    plt.imshow(image)    \n",
    "    image,steering = random_crop(image,steering,tx_lower=-20,tx_upper=20,ty_lower=-10,ty_upper=10)\n",
    "#    print('steering :',steering)\n",
    "#    plt.figure()\n",
    "#    plt.imshow(image)\n",
    "    image,steering = random_flip(image,steering)\n",
    "#    print('steering :',steering)\n",
    "#    plt.figure()\n",
    "#    plt.imshow(image)\n",
    "    \n",
    "    image = random_brightness(image)\n",
    "#    plt.figure()\n",
    "#    plt.imshow(image)\n",
    "    \n",
    "    return image,steering\n",
    "\n",
    "def get_validation_set(X_val,Y_val):\n",
    "    X = np.zeros((len(X_val),64,64,3))\n",
    "    Y = np.zeros(len(X_val))\n",
    "    for i in range(len(X_val)):\n",
    "        x,y = read_next_image(i,1,X_val,X_val,X_val,Y_val)\n",
    "        X[i],Y[i] = random_crop(x,y,tx_lower=0,tx_upper=0,ty_lower=0,ty_upper=0)\n",
    "    return X,Y\n",
    "    \n",
    "\n",
    "def generate_train_batch(X_train,X_left,X_right,Y_train,batch_size = 32):\n",
    "    \n",
    "    batch_images = np.zeros((batch_size, 64, 64, 3))\n",
    "    batch_steering = np.zeros(batch_size)\n",
    "    while 1:\n",
    "        for i_batch in range(batch_size):\n",
    "            x,y = generate_training_example(X_train,X_left,X_right,Y_train)\n",
    "            batch_images[i_batch] = x\n",
    "            batch_steering[i_batch] = y\n",
    "        yield batch_images, batch_steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train data type : object\n",
      "Y_train data type : float32\n",
      "X_val data type : float64\n",
      "Y_val data type : float64\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 64, 64, 3)     0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 16, 16, 32)    6176        lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 16, 16, 32)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 4, 4, 64)      131136      activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "relu2 (Activation)               (None, 4, 4, 64)      0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 2, 2, 128)     131200      relu2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 2, 2, 128)     0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 2, 2, 128)     65664       activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 2, 2, 128)     0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 512)           0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 512)           0           flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           65664       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 128)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 128)           0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 128)           16512       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1)             129         dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 416,481\n",
      "Trainable params: 416,481\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      "20000/20000 [==============================] - 45s - loss: 0.0681 - val_loss: 0.0213\n",
      "Epoch 2/30\n",
      "20000/20000 [==============================] - 43s - loss: 0.0296 - val_loss: 0.0122\n",
      "Epoch 3/30\n",
      "20000/20000 [==============================] - 43s - loss: 0.0250 - val_loss: 0.0113\n",
      "Epoch 4/30\n",
      "20000/20000 [==============================] - 43s - loss: 0.0222 - val_loss: 0.0122\n",
      "Epoch 5/30\n",
      "20000/20000 [==============================] - 43s - loss: 0.0212 - val_loss: 0.0117\n",
      "Epoch 6/30\n",
      "20000/20000 [==============================] - 43s - loss: 0.0200 - val_loss: 0.0113\n",
      "Epoch 7/30\n",
      "20000/20000 [==============================] - 43s - loss: 0.0200 - val_loss: 0.0111\n",
      "Epoch 8/30\n",
      "20000/20000 [==============================] - 43s - loss: 0.0196 - val_loss: 0.0116\n",
      "Epoch 9/30\n",
      "20000/20000 [==============================] - 43s - loss: 0.0197 - val_loss: 0.0114\n",
      "Epoch 10/30\n",
      "20000/20000 [==============================] - 43s - loss: 0.0195 - val_loss: 0.0108\n",
      "Epoch 11/30\n",
      "20000/20000 [==============================] - 43s - loss: 0.0183 - val_loss: 0.0113\n",
      "Epoch 12/30\n",
      "20000/20000 [==============================] - 42s - loss: 0.0180 - val_loss: 0.0106\n",
      "Epoch 13/30\n",
      "20000/20000 [==============================] - 43s - loss: 0.0182 - val_loss: 0.0106\n",
      "Epoch 14/30\n",
      "20000/20000 [==============================] - 43s - loss: 0.0183 - val_loss: 0.0105\n",
      "Epoch 15/30\n",
      "20000/20000 [==============================] - 42s - loss: 0.0183 - val_loss: 0.0111\n",
      "Epoch 16/30\n",
      "20000/20000 [==============================] - 42s - loss: 0.0173 - val_loss: 0.0111\n",
      "Epoch 17/30\n",
      "20000/20000 [==============================] - 42s - loss: 0.0173 - val_loss: 0.0116\n",
      "Epoch 18/30\n",
      "20000/20000 [==============================] - 43s - loss: 0.0174 - val_loss: 0.0111\n",
      "Epoch 19/30\n",
      "20000/20000 [==============================] - 43s - loss: 0.0181 - val_loss: 0.0115\n",
      "Epoch 20/30\n",
      "20000/20000 [==============================] - 43s - loss: 0.0174 - val_loss: 0.0110\n",
      "Epoch 21/30\n",
      "20000/20000 [==============================] - 43s - loss: 0.0175 - val_loss: 0.0106\n",
      "Epoch 22/30\n",
      "20000/20000 [==============================] - 42s - loss: 0.0177 - val_loss: 0.0118\n",
      "Epoch 23/30\n",
      "20000/20000 [==============================] - 43s - loss: 0.0168 - val_loss: 0.0109\n",
      "Epoch 24/30\n",
      "20000/20000 [==============================] - 43s - loss: 0.0170 - val_loss: 0.0113\n",
      "Epoch 25/30\n",
      "20000/20000 [==============================] - 43s - loss: 0.0169 - val_loss: 0.0112\n",
      "Epoch 26/30\n",
      "20000/20000 [==============================] - 42s - loss: 0.0164 - val_loss: 0.0111\n",
      "Epoch 27/30\n",
      "20000/20000 [==============================] - 43s - loss: 0.0166 - val_loss: 0.0107\n",
      "Epoch 28/30\n",
      "20000/20000 [==============================] - 42s - loss: 0.0161 - val_loss: 0.0110\n",
      "Epoch 29/30\n",
      "20000/20000 [==============================] - 42s - loss: 0.0170 - val_loss: 0.0112\n",
      "Epoch 30/30\n",
      "20000/20000 [==============================] - 43s - loss: 0.0162 - val_loss: 0.0108\n",
      "Training complete. Saving model and weights...\n",
      "Model and weights saved to home directory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "batch_size=200\n",
    "train_generator = generate_train_batch(X_train,X_left,X_right,Y_train,batch_size)\n",
    "X_val,Y_val = get_validation_set(X_val,Y_val)\n",
    "\n",
    "print('X_train data type :',X_train.dtype)\n",
    "print('Y_train data type :',Y_train.dtype)\n",
    "print('X_val data type :',X_val.dtype)\n",
    "print('Y_val data type :',Y_val.dtype)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/127.5 - 1.0,input_shape=(64,64,3)))\n",
    "model.add(Convolution2D(32, 8,8 ,border_mode='same', subsample=(4,4)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 8,8 ,border_mode='same',subsample=(4,4)))\n",
    "model.add(Activation('relu',name='relu2'))\n",
    "model.add(Convolution2D(128, 4,4,border_mode='same',subsample=(2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(128, 2,2,border_mode='same',subsample=(1,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(1))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "restart = True\n",
    "if os.path.isfile(model_json) and restart:\n",
    "    try:\n",
    "        with open(model_json) as jfile:\n",
    "            model = model_from_json(json.load(jfile))\n",
    "            model.load_weights(model_weights)    \n",
    "        print('loading trained model ...')\n",
    "    except Exception as e:\n",
    "        print('Unable to load model', model_name, ':', e)\n",
    "        raise    \n",
    "\n",
    "model.compile(optimizer=adam, loss='mse')\n",
    "\n",
    "EPOCHS = 30\n",
    "history = model.fit_generator(train_generator,\n",
    "                              samples_per_epoch=20000,\n",
    "                              nb_epoch=EPOCHS,\n",
    "                              validation_data=(X_val,Y_val),\n",
    "                              verbose=1)\n",
    "\n",
    "json_string = model.to_json()\n",
    "\n",
    "print('Training complete. Saving model and weights...')\n",
    "\n",
    "try:\n",
    "    os.remove(model_json)\n",
    "    os.remove(model_weights)\n",
    "except OSError:\n",
    "    pass   \n",
    "\n",
    "with open(model_json, 'w') as outfile:\n",
    "    json.dump(json_string, outfile)\n",
    "model.save_weights(model_weights)\n",
    "\n",
    "print('Model and weights saved to home directory.')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ScreenShot](Resources/Screenshots/loading_screen.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4 - Advanced Lane Finding Project\n",
    "\n",
    "### _Expanding on \"Project 1 - Finding Lane Lines\"_\n",
    "\n",
    "#### Please refer to this repository's README.md for a detailed explanation of the project: \n",
    "https://github.com/nhiddink/CarND_P4_Advanced_Lane_Finding/blob/master/README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://www.numpy.org/\n",
    "import numpy as np\n",
    "\n",
    "# http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_image_display/py_image_display.html\n",
    "import cv2\n",
    "\n",
    "# http://matplotlib.org/\n",
    "import matplotlib\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#%matplotlib qt\n",
    "\n",
    "# https://docs.python.org/2/library/pickle.html\n",
    "import pickle\n",
    "\n",
    "# https://docs.python.org/2/library/glob.html\n",
    "import glob\n",
    "\n",
    "# https://docs.python.org/2/library/os.html\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Camera Calibration\n",
    "#### Compute the camera calibration matrix and distortion coefficients given a set of chessboard images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('resources/camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Distortion Correction\n",
    "\n",
    "#### Apply a distortion correction to raw images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test undistortion on an image\n",
    "img = cv2.imread('resources/camera_cal/test_dist.jpg')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "# Do camera calibration given object points and image points\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "\n",
    "dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "cv2.imwrite('resources/camera_cal/test_undist.jpg',dst)\n",
    "\n",
    "# Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "pickle.dump(dist_pickle, open(\"resources/camera_cal/dist_pickle.p\", \"wb\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Undistortion using test_dist and test_undist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10));\n",
    "ax1.imshow(img);\n",
    "ax1.set_title('Original Image:\\n', fontsize=25)\n",
    "ax2.imshow(dst);\n",
    "ax2.set_title('Undistorted Image:\\n', fontsize=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Color & Gradient Thresholds\n",
    "Use color transforms, gradients, etc., to create a thresholded binary image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Display list of test images for reference:\n",
    "images = os.listdir(\"resources/test_images/\")\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=5):\n",
    "    \n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            slope = (y2-y1)/(x2-x1)\n",
    "            point = np.mean(line, axis=0)\n",
    "            y = point[1]\n",
    "            x = point[0]\n",
    "            if slope < 0: \n",
    "                intercept = y - slope*x\n",
    "                yLeft = intercept\n",
    "                yRight = slope * 960 + intercept\n",
    "                cv2.line(img, (0, int(yLeft)), (960, int(yRight)), color, thickness)\n",
    "            if slope > 0:\n",
    "                intercept = y - slope*x\n",
    "                yLeft = intercept\n",
    "                yRight = slope * 960 + intercept\n",
    "                cv2.line(img, (0, int(yLeft)), (960, int(yRight)), color, thickness)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    \n",
    "    line_img = np.zeros((*img.shape, 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "# Python 3 has support for cool math symbols.\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to run math functions/algorithms in one place. See last code cell in project for details.\n",
    "def main(img):\n",
    "    \n",
    "    #Read the image passed to main:\n",
    "    image = mpimg.imread(img)\n",
    "    \n",
    "    #Convert to grayscale, perform gaussian blur and canny edge detection:\n",
    "    gray = grayscale(image)\n",
    "    gauss = gaussian_blur(gray, 5)\n",
    "    can = canny(gauss, 50, 150)\n",
    "    \n",
    "    #Create a region of interest mask to eliminate extraneous edges:\n",
    "    shape = image.shape\n",
    "    vertices = np.array([[(0,shape[0]),(410, 340),(480, 310), (shape[1],shape[0])]], dtype=np.int32)\n",
    "    region = region_of_interest(can, vertices)\n",
    "    \n",
    "    #Perform a Hough transform and draw lines onto original image. See draw_lines function below for details.\n",
    "    rho = 2\n",
    "    theta = 1/180\n",
    "    threshold = 50\n",
    "    min_line_length = 10\n",
    "    max_line_gap = 20\n",
    "    hough = hough_lines(region, rho, theta, threshold, min_line_length, max_line_gap)\n",
    "    vertices2 = np.array([[(0,shape[0]),(410, 340),(480, 310), (shape[1],shape[0])]], dtype=np.int32)\n",
    "    \n",
    "    #Create a second region mask to crop extrapolating lines and format line weight:\n",
    "    region2 = region_of_interest(hough, vertices2)\n",
    "    weight = weighted_img(region2, image, α=0.8, β=1., λ=0.)\n",
    "    \n",
    "    #Display plot:\n",
    "    plt.imshow(weight);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Image: ' + images[0])\n",
    "main('resources/test_images/' + images[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Perspective Transform\n",
    "Apply a perspective transform to rectify binary image (\"birds-eye view\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V. Detecting Lane Lines\n",
    "Detect lane pixels and fit to find the lane boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VI. Determining Lane Curvature & Warping to Original Image\n",
    "\n",
    "Determine the curvature of the lane and vehicle position with respect to center.\n",
    "\n",
    "Warp the detected lane boundaries back onto the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VII. Output\n",
    "Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes & Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an image to draw the lines on\n",
    "warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "# Recast the x and y points into usable format for cv2.fillPoly()\n",
    "pts_left = np.array([np.transpose(np.vstack([left_fitx, yvals]))])\n",
    "pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, yvals])))])\n",
    "pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "# Draw the lane onto the warped blank image\n",
    "cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "# Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0])) \n",
    "# Combine the result with the original image\n",
    "result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lane Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I first take a histogram along all the columns in the lower half of the image like this:\n",
    "\n",
    "#img = INSERT_thresholded and warped image here!\n",
    "histogram = np.sum(img[img.shape[0]/2:,:], axis=0)\n",
    "plt.plot(histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Radius of curvature\n",
    "\n",
    "import numpy as np\n",
    "# Generate some fake data to represent lane-line pixels\n",
    "yvals = np.linspace(0, 100, num=101)*7.2  # to cover same y-range as image\n",
    "leftx = np.array([200 + (elem**2)*4e-4 + np.random.randint(-50, high=51) \n",
    "                              for idx, elem in enumerate(yvals)])\n",
    "leftx = leftx[::-1]  # Reverse to match top-to-bottom in y\n",
    "rightx = np.array([900 + (elem**2)*4e-4 + np.random.randint(-50, high=51) \n",
    "                                for idx, elem in enumerate(yvals)])\n",
    "rightx = rightx[::-1]  # Reverse to match top-to-bottom in y\n",
    "\n",
    "# Fit a second order polynomial to each fake lane line\n",
    "left_fit = np.polyfit(yvals, leftx, 2)\n",
    "left_fitx = left_fit[0]*yvals**2 + left_fit[1]*yvals + left_fit[2]\n",
    "right_fit = np.polyfit(yvals, rightx, 2)\n",
    "right_fitx = right_fit[0]*yvals**2 + right_fit[1]*yvals + right_fit[2]\n",
    "\n",
    "# Plot up the fake data\n",
    "plt.plot(leftx, yvals, 'o', color='red')\n",
    "plt.plot(rightx, yvals, 'o', color='blue')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(0, 720)\n",
    "plt.plot(left_fitx, yvals, color='green', linewidth=3)\n",
    "plt.plot(right_fitx, yvals, color='green', linewidth=3)\n",
    "plt.gca().invert_yaxis() # to visualize as we do the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define y-value where we want radius of curvature\n",
    "# I'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "y_eval = np.max(yvals)\n",
    "left_curverad = ((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) \\\n",
    "                             /np.absolute(2*left_fit[0])\n",
    "right_curverad = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) \\\n",
    "                                /np.absolute(2*right_fit[0])\n",
    "print(left_curverad, right_curverad)\n",
    "# Example values: 1163.9    1213.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define conversions in x and y from pixels space to meters\n",
    "ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/700 # meteres per pixel in x dimension\n",
    "\n",
    "left_fit_cr = np.polyfit(yvals*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "right_fit_cr = np.polyfit(yvals*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "left_curverad = ((1 + (2*left_fit_cr[0]*y_eval + left_fit_cr[1])**2)**1.5) \\\n",
    "                             /np.absolute(2*left_fit_cr[0])\n",
    "right_curverad = ((1 + (2*right_fit_cr[0]*y_eval + right_fit_cr[1])**2)**1.5) \\\n",
    "                                /np.absolute(2*right_fit_cr[0])\n",
    "# Now our radius of curvature is in meters\n",
    "print(left_curverad, 'm', right_curverad, 'm')\n",
    "# Example values: 3380.7 m    3189.3 m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "http://onlinemanuals.txdot.gov/txdotmanuals/rdw/horizontal_alignment.htm#BGBHGEGC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt Text](./resources/screenshots/loading_screen.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Udacity's Self-Driving Car Nanodegree Program\n",
    "### Project 5 - Vehicle Detection and Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please refer to this repository's README.md for a detailed explanation of the project: \n",
    "https://github.com/nhiddink/CarND_P5_Vehicle_Detection_and_Tracking/blob/master/README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://www.numpy.org/\n",
    "import numpy as np\n",
    "\n",
    "# http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_image_display/py_image_display.html\n",
    "import cv2\n",
    "\n",
    "# http://matplotlib.org/\n",
    "import matplotlib\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# https://docs.python.org/2/library/pickle.html\n",
    "import pickle\n",
    "\n",
    "# https://docs.python.org/2/library/glob.html\n",
    "import glob\n",
    "\n",
    "# https://docs.python.org/2/library/os.html\n",
    "import os\n",
    "\n",
    "# https://docs.python.org/2/library/math.html\n",
    "import math\n",
    "\n",
    "# http://zulko.github.io/moviepy/\n",
    "from moviepy.editor import VideoFileClip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section I: Camera Calibration and Distortion Correction\n",
    "\n",
    "##### Compute the camera calibration matrix and distortion coefficients given a set of chessboard images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "objpoints = []\n",
    "imgpoints = []\n",
    "\n",
    "images = glob.glob('resources/camera_cal/calibration*.jpg')\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        \n",
    "        #cv2.imshow('img', img)\n",
    "        #cv2.waitKey(500)\n",
    "\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apply a distortion correction to raw images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('resources/camera_cal/calibration2.jpg')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "\n",
    "dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "cv2.imwrite('resources/camera_cal/test_undist.jpg',dst)\n",
    "\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "pickle.dump(dist_pickle, open(\"resources/camera_cal/dist_pickle.p\", \"wb\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unwarp corners and visualize resulting images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist_pickle = pickle.load( open( \"resources/camera_cal/dist_pickle.p\", \"rb\" ) )\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "img = cv2.imread('resources/camera_cal/calibration2.jpg')\n",
    "nx = 8\n",
    "ny = 6\n",
    "def corners_unwarp(img, nx=nx, ny=ny, mtx=mtx, dist=dist):\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    gray = cv2.cvtColor(undist, cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "    if ret == True:\n",
    "        cv2.drawChessboardCorners(undist, (nx, ny), corners, ret)\n",
    "        offset = 100\n",
    "        img_size = (gray.shape[1], gray.shape[0])\n",
    "        src = np.float32([corners[0],\n",
    "                          corners[nx-1],\n",
    "                          corners[-1],\n",
    "                          corners[-nx]])\n",
    "        dst = np.float32([[offset, offset],\n",
    "                          [img_size[0]-offset, offset],\n",
    "                          [img_size[0]-offset, img_size[1]-offset], \n",
    "                          [offset, img_size[1]-offset]])\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "        warped = cv2.warpPerspective(undist, M, img_size)\n",
    "    return warped, M\n",
    "\n",
    "top_down, perspective_M = corners_unwarp(img, nx, ny, mtx, dist)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(25, 10))\n",
    "f.tight_layout()\n",
    "\n",
    "matplotlib.rc('xtick', labelsize=35) \n",
    "matplotlib.rc('ytick', labelsize=35)\n",
    "\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image: \\n', fontsize=35)\n",
    "ax2.imshow(top_down)\n",
    "ax2.set_title('Undistorted and Warped Image: \\n', fontsize=35)\n",
    "plt.subplots_adjust(left=0., right=1, top=1, bottom=0.)\n",
    "plt.savefig('resources/output_images/undistorted_and_warped.png', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotter(test_img, new_img, plot_title=None, n=0):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12.8,7.2))\n",
    "    f.tight_layout()\n",
    "    matplotlib.rc('xtick', labelsize=15) \n",
    "    matplotlib.rc('ytick', labelsize=15)\n",
    "    ax1.imshow(test_img)\n",
    "    ax1.set_title('Original Image:', fontsize=15)\n",
    "    ax2.imshow(new_img, cmap='gray')\n",
    "    ax2.set_title('{0} Test {1}:'.format(plot_title, n+1), fontsize=15)\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)\n",
    "def pipeline(op=None):\n",
    "    test_images = glob.glob('resources/test_images/test*.jpg')\n",
    "    n = 0\n",
    "    for img in test_images:\n",
    "        img = cv2.imread(img)\n",
    "        test_img = bgr_to_rgb(img)\n",
    "        if op == 'Undistorted':\n",
    "            new_img = undistort(img)\n",
    "            plotter(test_img, cv2.cvtColor(new_img, cv2.COLOR_BGR2RGB), op, n)\n",
    "            plt.savefig('resources/output_images/undistorted.png'.format(op), bbox_inches=\"tight\")\n",
    "            #break\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bgr_to_rgb(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def undistort(img):\n",
    "    mtx = dist_pickle['mtx']\n",
    "    dist = dist_pickle['dist']\n",
    "    return cv2.undistort(img, mtx, dist, None, mtx)            \n",
    "\n",
    "pipeline(op='Undistorted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section II: Feature Extraction and Training with a Linear SVM Classifier\n",
    "\n",
    "##### Visualize the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = glob.glob('resources/datasets/.jpg')\n",
    "cars = []\n",
    "not_cars = []\n",
    "\n",
    "for img in images:\n",
    "    if 'image' in image or 'extra' in image:\n",
    "        not_cars.append(img)\n",
    "    else:\n",
    "        cars.append(img)\n",
    "\n",
    "def visualize_data(car_list, notcar_list):\n",
    "    data_dict = {}\n",
    "    data_dict[\"n_cars\"] = len(car_list)\n",
    "    data_dict[\"n_notcars\"] = len(notcar_list)\n",
    "    img = mpimg.imread(car_list[0])\n",
    "    data_dict[\"image_shape\"] = example_img.shape\n",
    "    data_dict[\"data_type\"] = example_img.dtype\n",
    "    return data_dict\n",
    "\n",
    "visual = visualize_data(cars, not_cars)\n",
    "\n",
    "print('Your function returned a count of', \n",
    "      visual[\"n_cars\"], ' cars and', \n",
    "      visual[\"n_notcars\"], ' non-cars')\n",
    "print('of size: ',visual[\"image_shape\"], ' and data type:', \n",
    "      visual[\"data_type\"])\n",
    "\n",
    "car_id = np.random.randint(0, len(cars))\n",
    "notcar_id = np.random.randint(0, len(notcars))\n",
    "    \n",
    "car_image = mpimg.imread(cars[car_id])\n",
    "notcar_image = mpimg.imread(notcars[notcar_id])\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(car_image)\n",
    "plt.title('Example Car Image:')\n",
    "plt.subplot(122)\n",
    "plt.imshow(notcar_image)\n",
    "plt.title('Example Not-Car Image:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform feature extraction using a Histogram of Oriented Gradients (HOG) on a labeled training set of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apply color transforms and append binned color features and histograms of color to the HOG feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalize Features and Split Training Data for Testing and Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train a Linear SVM classifier using the labeled training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section III: Search for Vehicles in Images \n",
    "\n",
    "##### Implement a sliding-window technique to filter the image for possible vehicles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apply trained classifier to search for vehicles in sliding-window images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section IV: Test on a Video Stream\n",
    "\n",
    "##### Create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Estimate a bounding box for vehicles detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Output results as a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def video_pipeline(img):\n",
    "    \n",
    "    # TO DO\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_output = 'P5_test_video.mp4'\n",
    "clip = VideoFileClip('resources/test_videos/test_video.mp4')\n",
    "\n",
    "output_clip = clip.fl_image(video_pipeline)\n",
    "%time output_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#video_output = 'P5_project_video_final.mp4'\n",
    "#clip = VideoFileClip('resources/test_videos/project_video.mp4')\n",
    "\n",
    "#output_clip = clip.fl_image(video_pipeline)\n",
    "#%time output_clip.write_videofile(video_output, audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
